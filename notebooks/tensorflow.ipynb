{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that data saved is still present. Then load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloudclassifier.npy  cloudtrainingdata.csv  x_test.npy\t y_test.npy\r\n",
      "clouddata.npz.zip    testset.npy\t    x_train.npy  y_train.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('y_train.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing placeholders and parameters allows TensorFlow to build a dataflow graph\n",
    "def placeholders(n_x, n_y):\n",
    "    X = tf.placeholder(tf.float32, shape=(n_x, None), name=None)\n",
    "    Y = tf.placeholder(tf.float32, shape=(n_y, None), name=None)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def init_parameters():\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\", [1024,13358], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [1024,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [512,1024], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [512,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [64,512], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [64,1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [4,64], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b4 = tf.get_variable(\"b4\", [4,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3,\n",
    "                  \"W4\": W4,\n",
    "                  \"b4\": b4}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "#data is fed through a neural network via forward propagation in order to form a prediction\n",
    "def forward_prop(X, parameters):\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X), b1)                      \n",
    "    A1 = tf.nn.relu(Z1)                                   \n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2)                   \n",
    "    A2 = tf.nn.relu(Z2)                                   \n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3)  \n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    Z4 = tf.add(tf.matmul(W4,A3), b4)\n",
    "    \n",
    "    return Z4\n",
    "\n",
    "#measure probability error in predictions in order to alter and optimize weights\n",
    "def compute_cost(Z4, Y):\n",
    "   \n",
    "    logits = tf.transpose(Z4)\n",
    "    labels = tf.transpose(Y)\n",
    "   \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, learning_rate = 0.0001,\n",
    "          num_epochs = 200, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()                         \n",
    "    (n_x, m) = X_train.shape                          \n",
    "    n_y = Y_train.shape[0]                            \n",
    "    costs = []                                        \n",
    "    \n",
    "    #put the above functions together, and optimize weights' value and minimize cost via Adam optimizer and save trained parameters\n",
    "    X, Y = placeholders(n_x, n_y)\n",
    "    parameters = init_parameters()\n",
    "    Z4 = forward_prop(X, parameters)\n",
    "    cost = compute_cost(Z4, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            _ , epoch_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n",
    "            if print_cost == True and epoch % 20 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(Z4), tf.argmax(Y))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        \n",
    "        save_path = saver.save(sess, \"params.ckpt\",global_step=epoch)\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.549277\n",
      "Cost after epoch 20: 0.144776\n",
      "Cost after epoch 40: 0.061817\n",
      "Cost after epoch 60: 0.039667\n",
      "Cost after epoch 80: 0.028857\n",
      "Cost after epoch 100: 0.021995\n",
      "Cost after epoch 120: 0.017139\n",
      "Cost after epoch 140: 0.013576\n",
      "Cost after epoch 160: 0.010895\n",
      "Cost after epoch 180: 0.008858\n",
      "Parameters have been trained!\n",
      "Train Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "parameters = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained weights of network saved for further use. Check for addition of new files using ls command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t       params.ckpt-4.data-00000-of-00001  x_test.npy\r\n",
      "cloudclassifier.npy    params.ckpt-4.index\t\t  x_train.npy\r\n",
      "clouddata.npz.zip      params.ckpt-4.meta\t\t  y_test.npy\r\n",
      "cloudtrainingdata.csv  testset.npy\t\t\t  y_train.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
